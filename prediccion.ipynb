{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prediccion.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1VYuIhYuqUkvMJxzTfaLR3yUIls3Gw4qB","authorship_tag":"ABX9TyPh/6tj7rxtdN+STsOqXY7p"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MFngMqy0bryZ"},"source":["# DATATHON CAJAMAR: ATMIRA STOCK PREDICTION\r\n","\r\n","##PREDICCION DE DATOS A ESTIMAR\r\n","\r\n","### Equipo Enver\r\n","\r\n","Universidad Carlos III de Madrid\r\n","\r\n","2021"]},{"cell_type":"code","metadata":{"id":"iGvTwT82r6le"},"source":["#import os \r\n","#os.chdir(\"drive/MyDrive/Datathon\") #SE ASUME QUE EL WORKING DIRECTORY ES DONDE ESTA ESTE DIRECTORIO"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KACg39invIt"},"source":["import pandas as pd\r\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xvGy3mtKc3Tw"},"source":["def preparar_datos(data,estimar=False,product_ids=None): #procesamiento\r\n","\r\n","  new_data = data.copy()\r\n","  new_data['dia_atipico'] = new_data['dia_atipico'].astype('category')\r\n","  new_data['categoria_uno'] = new_data['categoria_uno'].astype('category')\r\n","  new_data['estado'] = new_data['estado'].astype('category')\r\n","\r\n","  #ordenar por id y fecha\r\n","  new_data = new_data.sort_values(['id','fecha'])\r\n","\r\n","  #eliminar categoria_dos, estado y antiguedad\r\n","  new_data.drop([\"categoria_dos\",'estado','antiguedad'],axis=1,inplace=True)\r\n","\r\n","  if estimar: #si es el dataset a estimar haremos que unidades_vendidas sea N/A \r\n","    new_data['unidades_vendidas'] = np.nan\r\n","\r\n","  new_data = new_data.set_index([\"id\",\"fecha\"])[['unidades_vendidas','visitas','precio','campaña']].unstack(level=-1) \r\n","\r\n","  #Si un producto no aparece en un periodo de tiempo se imputa como 0 para unidades_vendidas, visitas y campaña y como el ultimo precio que tenia para precio\r\n","  new_data['unidades_vendidas'] = new_data['unidades_vendidas'].fillna(0) if not estimar else np.nan\r\n","  new_data['visitas'] = new_data['visitas'].fillna(0)\r\n","  new_data['campaña'] = new_data['campaña'].fillna(0)\r\n","  new_data['precio'] = new_data['precio'].T.fillna(method='ffill').fillna(method='bfill').T\r\n","\r\n","  if product_ids is None:\r\n","    product_ids = data.id.sort_values().unique()\r\n","  \r\n","  new_data = new_data.loc[product_ids,:]\r\n","\r\n","  return new_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVa_WUKLoFlR"},"source":["## cargar datos\r\n","estimar_df = pd.read_table(\"raw_data/Estimar2.txt\", sep=\"|\", decimal=',', na_values=['-'])\r\n","modelar_df = pd.read_table(\"raw_data/Modelar_UH2021.txt\", sep=\"|\", decimal=',', na_values=['-'])#.sample(frac=0.1) #small sample for EDA\r\n","target_col = \"unidades_vendidas\"\r\n","\r\n","## preprocesamiento\r\n","\r\n","#cambiar fecha a tipo datetime\r\n","modelar_df['fecha'] = pd.to_datetime(modelar_df['fecha'],format=\"%d/%m/%Y %H:%M:%S\")\r\n","estimar_df['fecha'] = pd.to_datetime(estimar_df['fecha'],format=\"%Y-%m-%d\")\r\n","\r\n","#ordenar estimar y modelar por fecha e id\r\n","estimar_df = estimar_df.sort_values(['id','fecha'])\r\n","modelar_df = modelar_df.sort_values(['id','fecha'])\r\n","\r\n","#eliminar filas duplicadas de modelar\r\n","modelar_df.drop_duplicates(subset=['fecha','id'],inplace=True)\r\n","\r\n","#el dataset a estimar no contiene valores con estado=Rotura asi que eliminaremos esos del modelar\r\n","modelar_df = modelar_df[modelar_df.estado!='Rotura']\r\n","\r\n","#tambien hay ids del modelar que no existen en el estimar, como no proveen informacion extra los quitaremos de aqui\r\n","modelar_df = modelar_df[modelar_df.id.isin(estimar_df.id)] #eliminar ids que no esten en el conjunto a estimar\r\n","\r\n","#imputar valores no existentes en precio por sus mas cercanos en el pasado en modelar\r\n","id_dfs = [modelar_df[modelar_df.id==id_].fillna(method='ffill').fillna(method='bfill') for id_ in modelar_df.id.unique()]\r\n","modelar_df = pd.concat(id_dfs,axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oriZdtl0pMu-"},"source":["#preparar datos para el modelado\r\n","modelar_processed = preparar_datos(modelar_df)\r\n","estimar_processed = preparar_datos(estimar_df,estimar=True)\r\n","\r\n","#combinar estos datos por fecha\r\n","df = pd.concat([modelar_processed,estimar_processed],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"phLcc4SySBCp"},"source":["#dataset de categorias por producto\r\n","categorias_df = modelar_df[['id','categoria_uno']].drop_duplicates()\r\n","\r\n","#dataset de dias atipicos\r\n","dias_atipicos = pd.concat((estimar_df[['fecha','dia_atipico']],modelar_df[['fecha','dia_atipico']]),axis=0).drop_duplicates()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YPkrrADov8_E"},"source":["Lo siguiente es una funcion pipeline que dado un dataframe con una fila para cada uno de los $p$ productos, un dia `d` y numero entero `days_to_pred` devuelve un dataframe nuevo con : \r\n","\r\n","1. Nuevas variables basadas en los valores futuros a `d` de `visitas`, `campaña` y `precio` por cada uno de los `days_to_pred` dias a predecir. \r\n","2. Nuevas variables sacando la media de variables como `visitas`, `unidades_vendidas` y `precio` de $n$ dias pasados a `d` para varias $n$. \r\n","3. Nuevas variables basadas en pasados dias de campaña (Como el numero de veces que el producto ha estado en campaña en los ultimos $n$ dias para varias $n$) y tambien basado en futuros dias de campañá (Si/no habran dias de campaña en el futuro cercano por ejemplo).\r\n","4. Variables dummies para las variables categoricas como `dia_atipico` y `categoria_uno`.\r\n","\r\n","Por esto el dataset de entrada a esta pipeline es indexado por el `id` del producto en sus filas y por `fecha` en sus columnas como hemos hecho arriba."]},{"cell_type":"code","metadata":{"id":"9z5DWb2930Fo"},"source":["def transform_pipeline(df,d,df_after = None,days_to_pred=30): #funcion de pipeline\r\n","  '''\r\n","  Recibe un dataset df y dia d y genera nuevas variables temporales basada en los dias `days_to_pred` a predecir\r\n","  '''\r\n","  if df_after is None:\r\n","    df_after = df#.loc[:,(np.unique([r[0] for r in df.columns]),pd.date_range(d, periods=days_to_pred, freq='d') )]\r\n","  def get_values_on_period(df,days_before,days_length):\r\n","    date_range = pd.date_range(d-pd.to_timedelta(days_before,'days'),d-pd.to_timedelta(days_before,'days')+pd.to_timedelta(days_length-1,'days'))\r\n","    date_range = date_range[~date_range.astype(str).str.contains('02-29')]\r\n","    return df[date_range]\r\n","  #1. Informacion de los dias a predecir\r\n","  X_list = [\r\n","       pd.DataFrame({\r\n","            f'visitas_{i}_despues' : df_after['visitas'][d+pd.to_timedelta(i,'days')].values.ravel(),\r\n","            f'precio_{i}_despues' : df_after['precio'][d+pd.to_timedelta(i,'days')].values.ravel(),\r\n","            f'campana_{i}_despues' : df_after['campaña'][d+pd.to_timedelta(i,'days')].values.ravel(),\r\n","            f'demanda_alta_{i}_despues': (dias_atipicos[dias_atipicos.fecha==d+pd.to_timedelta(i,'days')].dia_atipico==1).astype(int).tolist()*len(df),\r\n","            f'demanda_baja_{i}_despues': (dias_atipicos[dias_atipicos.fecha==d+pd.to_timedelta(i,'days')].dia_atipico==-1).astype(int).tolist()*len(df),\r\n","            }\r\n","        ) for i in range(days_to_pred) if d+pd.to_timedelta(i,'days') in df_after['visitas'].columns\r\n","  ]\r\n","  #1. Informacion del pasado\r\n","  X_list = X_list + [\r\n","       pd.DataFrame({\r\n","            f'{var}_1_antes': get_values_on_period(df[var],1,1).values.ravel(),\r\n","            f'{var}_7_antes_avg': get_values_on_period(df[var],7,7).values.mean(axis=1),\r\n","            f'{var}_14_antes_avg': get_values_on_period(df[var],14,14).values.mean(axis=1),\r\n","            f'{var}_28_antes_avg': get_values_on_period(df[var],28,28).values.mean(axis=1),\r\n","            f'{var}_60_antes_avg': get_values_on_period(df[var],60,60).values.mean(axis=1),\r\n","            #f'{var}_120_antes_avg': get_values_on_period(df[var],120,120).values.mean(axis=1),\r\n","            }\r\n","        ) for var in ['unidades_vendidas','precio','visitas']\r\n","  ]\r\n","  #2.\r\n","  X_list = X_list + [ #conteo de cuantas veces el producto ha estado en campaña en dias pasados\r\n","       pd.DataFrame({\r\n","               f'count_campana_{i}_antes': get_values_on_period(df['campaña'],i,i).values.sum(axis=1) for i in [1,7,14,30]\r\n","               })\r\n","       ]\r\n","  X_list = X_list + [ #variables binaricas indicando si el producto estara en campaña cada dia de las proximas dos semanas\r\n","       pd.DataFrame({\r\n","               f'is_campana_{i}_despues': get_values_on_period(df['campaña'],i,i).values.sum(axis=1) for i in range(14)\r\n","               })\r\n","       ]\r\n","  #3.\r\n","  X_list = X_list + [ #dummies de categoria_uno\r\n","       pd.DataFrame({\r\n","               f'categoria_uno_{cat}': df.index.isin(categorias_df[categorias_df.categoria_uno==cat].id).astype(int) for cat in categorias_df.categoria_uno\r\n","               })\r\n","       ]\r\n","  X_list = X_list + [ #dummies de dia_atipico\r\n","       pd.DataFrame({\r\n","           f'demanda_alta_1_antes': [get_values_on_period(df['visitas'],1,1).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==1].fecha).sum()]*len(df),\r\n","           f'conteo_demanda_alta_7_antes': [get_values_on_period(df['visitas'],7,7).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==1].fecha).sum()]*len(df),\r\n","           f'conteo_demanda_alta_15_antes': [get_values_on_period(df['visitas'],15,15).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==1].fecha).sum()]*len(df),\r\n","           f'conteo_demanda_alta_30_antes': [get_values_on_period(df['visitas'],30,30).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==1].fecha).sum()]*len(df),\r\n","           f'conteo_demanda_alta_60_antes': [get_values_on_period(df['visitas'],60,60).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==1].fecha).sum()]*len(df),\r\n","           f'demanda_baja_1_antes': [get_values_on_period(df['visitas'],1,1).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==-1].fecha).sum()]*len(df),\r\n","           f'conteo_demanda_baja_7_antes': [get_values_on_period(df['visitas'],7,7).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==-1].fecha).sum()]*len(df),\r\n","           f'conteo_demanda_baja_15_antes': [get_values_on_period(df['visitas'],15,15).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==-1].fecha).sum()]*len(df),\r\n","           f'conteo_demanda_baja_30_antes': [get_values_on_period(df['visitas'],30,30).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==-1].fecha).sum()]*len(df),\r\n","           f'conteo_demanda_baja_60_antes': [get_values_on_period(df['visitas'],60,60).columns.isin(dias_atipicos[dias_atipicos.dia_atipico==-1].fecha).sum()]*len(df),\r\n","           })\r\n","       ]\r\n","  X = pd.concat(X_list,axis=1)\r\n","  \r\n","  return X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bQGqt85ZM1qJ"},"source":["La funcion de pipeline definida arriba sera usada para obtener los conjuntos $X$ e $Y$ de entrenamiento que definiran respectivamente las variables que seran usadas para predecir y el target de cada modelo. Esta funcion obtiene un numero $m$ de variables temporales de hasta los ultimos $n$ dias del dataframe dado. Para tomar ventaja de los datos que nos han dado para modelar (que tienen un periodo de un año y medio) tomaremos $b$ \"batches\" de estos datos, cada uno con un periodo de alrededor de 3 meses, y por cada batch obtendremos $p$ nuevas filas para usar en el train. \r\n","\r\n","El dataframe que usaremos para entrenar tendra por lo tanto $b\\cdot p$ filas y $m$ columnas."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"3wQIme5QMq2K","executionInfo":{"status":"ok","timestamp":1615978172949,"user_tz":-60,"elapsed":54203,"user":{"displayName":"Simon Sanchez Viloria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHIZ5JDNs75yNil4NRoCm1IyTfYYBfeQLvdLXP=s64","userId":"15163509617515403355"}},"outputId":"0655013b-f510-4763-b09d-841f909626e1"},"source":["#Obtener conjuntos X e Y que seran usados para entrenar y estimar\r\n","\r\n","b = 8 #numero de\"batches\"\r\n","batch_spacing = 45 #Numero de dias que separan un batch del otro\r\n","\r\n","from fastprogress import progress_bar\r\n","\r\n","estimar_from_date = estimar_df.fecha.iloc[0] #dia donde empieza la estimacion\r\n","n_days_to_pred = estimar_df.fecha.nunique() #numero de dias que predecir\r\n","\r\n","X_estimar = transform_pipeline(df,estimar_from_date,days_to_pred=n_days_to_pred)\r\n","Y_hat_estimar = pd.DataFrame(data=None,index=df.index,columns=estimar_processed['unidades_vendidas'].columns) #dataset vacio que sera llenado luego cuando se saquen las predicciones\r\n","\r\n","estimar_begin = df['precio'][pd.date_range(estimar_from_date, periods=n_days_to_pred, freq='d').difference([pd.to_datetime(\"2016-02-29\")])].columns[0] #solo para asegurarse de que la fecha donde se empieza a estimar esta en df\r\n","estimar_end = df['precio'][pd.date_range(estimar_from_date, periods=n_days_to_pred, freq='d').difference([pd.to_datetime(\"2016-02-29\")])].columns[-1]\r\n","\r\n","assert estimar_end >= estimar_df.fecha.iloc[-1], \"No estas estimando todo el conjunto a estimar\"\r\n","assert estimar_begin <= estimar_df.fecha.iloc[0], \"No estas estimando desde el inicio del conjunto a estimar\"\r\n","\r\n","vars = ['unidades_vendidas','visitas','precio','campaña']\r\n","train_end = estimar_begin - pd.to_timedelta(1,unit='days')\r\n","df_train = df.loc[:,(vars,pd.date_range(start=modelar_df.fecha.iloc[0], end=train_end ))]\r\n","\r\n","assert train_end - pd.to_timedelta(batch_spacing*(b-1)+n_days_to_pred+61,'days')  > modelar_df.fecha.iloc[0], \"La fecha de train_begin debe ser posterior a la primera fecha disponible en el conjunto de modelar. Reduce b o batch_spacing\"\r\n","\r\n","X_list = []\r\n","Y_list = []\r\n","train_batch_end = train_end-pd.to_timedelta(n_days_to_pred,unit='days') \r\n","print(\"OBTENIENDO CONJUNTO DE ENTRENAMIENTO...\")\r\n","for i in progress_bar(range(b)):\r\n","  train_batch_start = train_batch_end - pd.to_timedelta(61,'days') \r\n","  day_target_start = train_batch_end+pd.to_timedelta(1,unit='days')\r\n","\r\n","  train_period = pd.date_range(start=train_batch_start,end=train_batch_end)\r\n","  target_period = pd.date_range(day_target_start, periods=n_days_to_pred, freq='d')\r\n","  target_period = target_period if \"2016-02-29\" not in target_period else pd.date_range(day_target_start, periods=n_days_to_pred+1, freq='d').difference([pd.to_datetime(\"2016-02-29\")])\r\n","\r\n","  batch_df = df.loc[:,(vars,train_period)]\r\n","  days_after_df = df.loc[:,(('visitas','precio','campaña'),target_period)]\r\n","\r\n","  X_batch = transform_pipeline(batch_df,day_target_start,days_after_df,n_days_to_pred)#.add_suffix(f\"_b{i+1}\")  \r\n","  Y_batch = df['unidades_vendidas'][target_period]\r\n","  Y_batch.columns = list(range(1,n_days_to_pred+1))\r\n","\r\n","  X_list.append(X_batch); Y_list.append(Y_batch);   \r\n","  train_batch_end = train_batch_end - pd.to_timedelta(batch_spacing,unit='days')\r\n","\r\n","X_train = pd.concat(X_list)\r\n","y_train = pd.concat(Y_list)\r\n","\r\n","print(\"\\nFecha donde empieza el conjunto a entrenar:\",str(train_batch_start)) \r\n","print(\"Fecha donde termina el conjunto a entrenar:\",str(train_end)) \r\n","print(\"Tamaño del conjunto a entrenar transformado:\",X_train.shape)\r\n","\r\n","print(\"\\nFecha donde empieza el conjunto a estimar:\",str(estimar_begin))\r\n","print(\"Fecha donde termina el conjunto a estimar:\",str(estimar_end))\r\n","print(\"Tamaño del conjunto a estimar transformado:\",X_estimar.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["OBTENIENDO CONJUNTO DE ENTRENAMIENTO...\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='8' class='' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [8/8 00:25<00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Fecha donde empieza el conjunto a entrenar: 2015-06-20 00:00:00\n","Fecha donde termina el conjunto a entrenar: 2016-09-30 00:00:00\n","Tamaño del conjunto a entrenar transformado: (21888, 516)\n","\n","Fecha donde empieza el conjunto a estimar: 2016-10-01 00:00:00\n","Fecha donde termina el conjunto a estimar: 2016-12-31 00:00:00\n","Tamaño del conjunto a estimar transformado: (2736, 516)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gwZ7JfEDbngt"},"source":["## Metrica para early stopping:\r\n","from sklearn.metrics import mean_squared_error\r\n","rRMSE = lambda y_true,y_pred: mean_squared_error(y_true,y_pred,squared=False)/y_true.mean()\r\n","def my_score_function(y_true, y_pred):\r\n","  CF = sum(y_pred>=y_true)/len(y_true)\r\n","  rRMSE = mean_squared_error(y_true,y_pred,squared=False)/y_true.mean()\r\n","  return 0.7*rRMSE+(0.3*(1-CF))\r\n","\r\n","my_score_fun = lambda y_hat, y: ('my_score_fun',my_score_function(y.get_label(),y_hat))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"eNyIDOrglrOt","executionInfo":{"status":"ok","timestamp":1615978743762,"user_tz":-60,"elapsed":624989,"user":{"displayName":"Simon Sanchez Viloria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHIZ5JDNs75yNil4NRoCm1IyTfYYBfeQLvdLXP=s64","userId":"15163509617515403355"}},"outputId":"52bce151-f6e5-41a0-ab35-0729b5172bc7"},"source":["import xgboost as xgb\r\n","xgb_params = {\r\n","    \"objective\": \"reg:squarederror\",\r\n","    'n_estimators':400,\r\n","    \"eta\": 0.07,\r\n","    \"subsample\": 0.8,\r\n","    'max_depth':6,\r\n","    'verbosity':0,\r\n","    'silent':0,\r\n","}\r\n","\r\n","def train_xgb(X_train,Y_train,X_test,Y_test,params,feval):\r\n","  dtrain = xgb.DMatrix(X_train,Y_train)\r\n","  dtest = xgb.DMatrix(X_test,Y_test) if X_test is not None else None\r\n","  watchlist = [(dtrain, 'train'), (dtest, 'test')] if dtest is not None else [(dtrain, 'train')]\r\n","  gbm = xgb.train(params, dtrain, num_boost_round=20, evals = watchlist, early_stopping_rounds = 5, feval = feval,verbose_eval=0)\r\n","  if dtest is not None:\r\n","    pred = gbm.predict(dtest)\r\n","    eval_metric = my_score_function(Y_test,pred)\r\n","  else:\r\n","    eval_metric = np.nan\r\n","  return (eval_metric,gbm)\r\n","\r\n","print(\"ENTRENANDO CADA UNO DE LOS %s MODELOS...\"%n_days_to_pred)\r\n","results = {}\r\n","for j in progress_bar(range(n_days_to_pred)):\r\n","  #print(f\"{i+1}/{train_X.id.nunique()},{id_}\")\r\n","  y_tr_j = y_train.iloc[:,j]\r\n","  results[j+1] = train_xgb(X_train,y_tr_j,None,None,xgb_params,my_score_fun)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ENTRENANDO CADA UNO DE LOS 92 MODELOS...\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='92' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [92/92 09:30<00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"6lKLiqFWEZ9X","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1615978744240,"user_tz":-60,"elapsed":625456,"user":{"displayName":"Simon Sanchez Viloria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHIZ5JDNs75yNil4NRoCm1IyTfYYBfeQLvdLXP=s64","userId":"15163509617515403355"}},"outputId":"5aeff23e-f2ff-4277-accf-59436815bb7e"},"source":["#predicciones:\r\n","print(\"OBTENIENDO PREDICCIONES...\")\r\n","D_estimar = xgb.DMatrix(X_estimar)\r\n","for j in progress_bar(range(n_days_to_pred)):\r\n","  yhat = results[j+1][1].predict(D_estimar)\r\n","  Y_hat_estimar.iloc[:,j] = yhat"],"execution_count":null,"outputs":[{"output_type":"stream","text":["OBTENIENDO PREDICCIONES...\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='92' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [92/92 00:00<00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"bbRQuhxzTVVE","executionInfo":{"status":"ok","timestamp":1615978763684,"user_tz":-60,"elapsed":644883,"user":{"displayName":"Simon Sanchez Viloria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHIZ5JDNs75yNil4NRoCm1IyTfYYBfeQLvdLXP=s64","userId":"15163509617515403355"}},"outputId":"2cd2b245-957b-4181-fdfe-bf73f4c683b0"},"source":["#cambiar al formato adecuado para la entrega:\r\n","entrega = pd.DataFrame(data=None,columns=['FECHA','ID','UNIDADES'])\r\n","print(\"OBTENIENDO DATASET DE ENTREGA...\")\r\n","for id in progress_bar(estimar_df.id.unique()):\r\n","  id_fechas = estimar_df[estimar_df.id==id].fecha\r\n","  df = pd.DataFrame({'FECHA':id_fechas,'ID':[id]*len(id_fechas),'UNIDADES':Y_hat_estimar.loc[id,id_fechas].values})\r\n","  entrega = entrega.append(df)\r\n","\r\n","assert all(entrega.FECHA.isin(estimar_df.fecha)) and all(estimar_df.fecha.isin(entrega.FECHA)) and all(entrega.ID.isin(estimar_df.id)) and all(estimar_df.id.isin(entrega.ID)), \"Hay algo mal con el dataset de entrega!\"\r\n","\r\n","#post-procesamiento\r\n","entrega.UNIDADES = np.ceil(np.where(entrega.UNIDADES<1,0,entrega.UNIDADES)).astype(int)\r\n","entrega.FECHA = entrega.FECHA.dt.strftime(\"%d/%m/%Y\")\r\n","entrega"],"execution_count":null,"outputs":[{"output_type":"stream","text":["OBTENIENDO DATASET DE ENTREGA...\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='2736' class='' max='2736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [2736/2736 00:17<00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FECHA</th>\n","      <th>ID</th>\n","      <th>UNIDADES</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01/10/2016</td>\n","      <td>21972</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>02/10/2016</td>\n","      <td>21972</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>03/10/2016</td>\n","      <td>21972</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>04/10/2016</td>\n","      <td>21972</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>05/10/2016</td>\n","      <td>21972</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>212836</th>\n","      <td>26/12/2016</td>\n","      <td>458660</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>212837</th>\n","      <td>27/12/2016</td>\n","      <td>458660</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>212838</th>\n","      <td>28/12/2016</td>\n","      <td>458660</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>212839</th>\n","      <td>29/12/2016</td>\n","      <td>458660</td>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>212840</th>\n","      <td>30/12/2016</td>\n","      <td>458660</td>\n","      <td>68</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>212841 rows × 3 columns</p>\n","</div>"],"text/plain":["             FECHA      ID  UNIDADES\n","0       01/10/2016   21972         2\n","1       02/10/2016   21972         3\n","2       03/10/2016   21972         2\n","3       04/10/2016   21972         2\n","4       05/10/2016   21972         2\n","...            ...     ...       ...\n","212836  26/12/2016  458660        35\n","212837  27/12/2016  458660        46\n","212838  28/12/2016  458660        40\n","212839  29/12/2016  458660        63\n","212840  30/12/2016  458660        68\n","\n","[212841 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"knEtDMceUMn9"},"source":["#Exportar como archivo de texto con el formato adecuado:\r\n","entrega.to_csv(\"Enver.txt\",sep=\"|\",decimal=\",\",index=False)"],"execution_count":null,"outputs":[]}]}